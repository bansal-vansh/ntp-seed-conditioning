{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f99084a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cluster/vansh/miniconda/envs/ml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os, sys\n",
    "device = 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(device)\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from transformers import PreTrainedTokenizer\n",
    "import json\n",
    "\n",
    "from data.dataset import CustomTokenizer\n",
    "from transformers import GPT2Config\n",
    "from data.circle import make_dataset, compute_canonical_permutation\n",
    "from model.networks import AttentionOnlyLMHeadModel\n",
    "from model.eval import decode_batch, generate_samples, compute_perplexity\n",
    "from model.train import train_main\n",
    "from model.utils import set_seed\n",
    "from data.dataset import collate_fn\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17269816",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(f\"cuda:{0}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# define dataset parameters\n",
    "dataset_name = \"circle\"\n",
    "model_type = \"attention-only-12\"\n",
    "model_path = None\n",
    "\n",
    "M = 15\n",
    "N = 9\n",
    "H = 26\n",
    "HL = 5\n",
    "seed_per_pi = False\n",
    "num_train_samples =10000\n",
    "batch_size = 32\n",
    "num_eval_samples = 1000\n",
    "eval_batch_size = 256\n",
    "num_ckpts = 20\n",
    "epochs = 20\n",
    "eval_runs = 1\n",
    "top_p=1.0\n",
    "save_name = f\"M{M}-N{N}-H{H}-NT{num_train_samples}-E{epochs}-top_p{top_p}-{model_type}\"\n",
    "data_root = f\"/datastor1/vansh/lang_sampling/data\"\n",
    "regenerate_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae791ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS token: <BOS>, ID: 0\n",
      "EOS token: <EOS>, ID: 1\n",
      "PAD token: <EOS>, ID: 1\n",
      "Loading existing dataset from /datastor1/vansh/lang_sampling/data/circle/M15-N9\n",
      "Generated 11000 unique seeds for the strings.\n",
      "Pre-calculating all training seeds...\n",
      "Pre-calculating all training seeds...\n"
     ]
    }
   ],
   "source": [
    "tokenizer = CustomTokenizer()\n",
    "\n",
    "train_dataset, test_dataset, tokenizer, train_strs, train_perms, VOCAB, SEED_TOKENS, EVAL_TOKENIZER = make_dataset(\n",
    "                                                                                                                    M=M,\n",
    "                                                                                                                    N=N,\n",
    "                                                                                                                    H=H,\n",
    "                                                                                                                    seed_len=HL,\n",
    "                                                                                                                    seed_per_pi=seed_per_pi,\n",
    "                                                                                                                    num_train_samples=num_train_samples,\n",
    "                                                                                                                    num_test_samples=num_eval_samples,\n",
    "                                                                                                                    tokenizer=tokenizer,\n",
    "                                                                                                                    data_root=data_root,\n",
    "                                                                                                                    regenerate=regenerate_data\n",
    "                                                                                                                )\n",
    "VOCAB_IDs = {EVAL_TOKENIZER._convert_token_to_id(tok) for tok in VOCAB}\n",
    "data_collator = lambda features: collate_fn(features, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42bfc9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing new attention-only-12 model from scratch\n",
      "Model attention-only-12 initialized with 29182464 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "model_name = model_type.removesuffix(\"-pretrained\")\n",
    "\n",
    "if model_name == 'attention-only-2':\n",
    "    config = GPT2Config(\n",
    "        vocab_size=tokenizer.vocab_size, n_positions=128, n_layer=2,\n",
    "        n_head=4, n_embd=128, bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "elif model_name == 'attention-only-4':\n",
    "    config = GPT2Config(\n",
    "        vocab_size=tokenizer.vocab_size, n_positions=256, n_layer=4,\n",
    "        n_head=8, n_embd=256, bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "elif model_name == 'attention-only-12':\n",
    "    config = GPT2Config(\n",
    "        vocab_size=tokenizer.vocab_size, n_positions=1024, n_layer=12,\n",
    "        n_head=12, n_embd=768, bos_token_id=tokenizer.bos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id, pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"No configuration defined for model type {model_type}\")\n",
    "\n",
    "# 3. Instantiate the model from scratch or load from a path\n",
    "if \"pretrained\" in model_type:\n",
    "    if not model_path:\n",
    "        raise ValueError(\"Must provide 'model_path' in args when using a pretrained model.\")\n",
    "    print(f\"Loading pretrained {model_name} model from {model_path}\")\n",
    "    model = AttentionOnlyLMHeadModel.from_pretrained(model_path)\n",
    "else:\n",
    "    print(f\"Initializing new {model_name} model from scratch\")\n",
    "    model = AttentionOnlyLMHeadModel(config=config)\n",
    "\n",
    "model.to(DEVICE)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "print(f\"Model {model_name} initialized with {sum(p.numel() for p in model.parameters() if p.requires_grad)} trainable parameters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6912e8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training permutations set size: 8870\n"
     ]
    }
   ],
   "source": [
    "train_perms_set = set(train_perms)\n",
    "print(f\"Training permutations set size: {len(train_perms_set)}\")\n",
    "\n",
    "def is_coherent_after_walk(seq, N, vocab_ids=VOCAB_IDs) -> bool:\n",
    "    \"\"\"\n",
    "    Given that Ï€ exists (walk succeeded), check coherence:\n",
    "    - correct number of edges\n",
    "    - correct tokens\n",
    "    \"\"\"\n",
    "    if len(seq) != 2 * N:\n",
    "        return False\n",
    "\n",
    "    vocab_set = set(vocab_ids)\n",
    "    if any(token not in vocab_set for token in seq):\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def evaluate_model(model, \n",
    "                greedy, \n",
    "                temperature, \n",
    "                label, \n",
    "                decode_fn, \n",
    "                train_dataset, \n",
    "                seed=42, \n",
    "                batch_size=eval_batch_size, \n",
    "                num_eval_samples=num_eval_samples,\n",
    "                top_p=top_p):\n",
    "    set_seed(seed)\n",
    "    print(f\"\\nEvaluating {label} for seed {seed}...\")\n",
    "\n",
    "    samples = generate_samples(model, \n",
    "                                train_dataset, \n",
    "                                tokenizer,\n",
    "                                decode_fn=decode_fn, \n",
    "                                greedy=greedy, \n",
    "                                seed_tokens=SEED_TOKENS, \n",
    "                                seed_len=HL, \n",
    "                                max_length=train_dataset[1][\"labels\"].shape[0]*2,\n",
    "                                temperature=temperature, \n",
    "                                top_p=top_p, \n",
    "                                num_samples=num_eval_samples, \n",
    "                                batch_size=batch_size\n",
    "                                )\n",
    "    tokenized_samples = [EVAL_TOKENIZER.encode(s) for s in samples]\n",
    "\n",
    "    unique_perms = set()\n",
    "    unique_coherent_perms = set()\n",
    "    num_coherent = 0\n",
    "    incoherent_samples = []\n",
    "    # Final metrics loop\n",
    "    for s in tokenized_samples:\n",
    "        pi = compute_canonical_permutation(s, N=N)\n",
    "        if pi is not None:\n",
    "            unique_perms.add(pi)\n",
    "            if is_coherent_after_walk(s, N=N, vocab_ids=VOCAB_IDs):\n",
    "                num_coherent += 1\n",
    "                unique_coherent_perms.add(pi)\n",
    "            else:\n",
    "                incoherent_samples.append(s)\n",
    "        else:\n",
    "            incoherent_samples.append(s)\n",
    "\n",
    "    num_unique_samples = len(set([tuple(s) for s in tokenized_samples])) \n",
    "\n",
    "    num_memorized = len([s for s in unique_coherent_perms if s in train_perms_set])\n",
    "    num_creative = len([s for s in unique_coherent_perms if s not in train_perms_set])\n",
    "    num_unique_perms = len(unique_perms)\n",
    "\n",
    "    representation_power = (num_memorized / len(samples))\n",
    "    creativity = (num_creative / len(samples)) \n",
    "    uniqueness = (num_unique_perms / len(samples)) \n",
    "    coherence = (num_coherent / len(samples)) \n",
    "\n",
    "    uniqueness_strings = (num_unique_samples / len(samples)) \n",
    "    # perplexity = compute_perplexity(model, test_dataset, batch_size=batch_size)\n",
    "\n",
    "    # print(f\"Perplexity: {perplexity:.4f}\")\n",
    "    print(f\"Coherence: {coherence:.4f} ({num_coherent}/{len(samples)})\")\n",
    "    print(f\"Representation power: {representation_power:.4f} ({num_memorized}/{len(samples)})\")\n",
    "    print(f\"Creativity: {creativity:.4f} ({num_creative}/{len(samples)})\")\n",
    "    print(f\"Uniqueness (permutations): {uniqueness:.4f} ({num_unique_perms}/{len(samples)})\")\n",
    "    print(f\"Uniqueness (strings): {uniqueness_strings:.4f} ({num_unique_samples}/{len(samples)})\")\n",
    "\n",
    "    return np.array([\n",
    "        representation_power,\n",
    "        creativity,\n",
    "        uniqueness,\n",
    "        coherence,\n",
    "        len(samples)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766114e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Learning Rate Finder ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 93/100 [00:03<00:00, 28.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping early, the loss has diverged\n",
      "Learning rate search finished. See the graph with {finder_name}.plot()\n",
      "LR suggestion: steepest gradient\n",
      "Suggested LR: 6.58E-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder plot saved to lr_finder.png\n",
      "\n",
      "--- LR Finder complete. You can now use the suggested LR for training. ---\n"
     ]
    }
   ],
   "source": [
    "# from torch_lr_finder import LRFinder, TrainDataLoaderIter\n",
    "# import torch.optim as optim\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class HFTrainLoaderIter(TrainDataLoaderIter):\n",
    "#     def inputs_labels_from_batch(self, batch_data):\n",
    "#         return batch_data, batch_data[\"labels\"]\n",
    "\n",
    "# class ModelWrapper(nn.Module):\n",
    "#     def __init__(self, model):\n",
    "#         super().__init__()\n",
    "#         self.model = model\n",
    "\n",
    "#     def forward(self, inputs):\n",
    "#         return self.model(**inputs)\n",
    "\n",
    "# def hf_criterion(outputs, labels):\n",
    "#     return outputs.loss\n",
    "\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=batch_size, # Use the same batch size as your main training\n",
    "#     collate_fn=data_collator,\n",
    "#     shuffle=True\n",
    "# )\n",
    "\n",
    "\n",
    "# # --- LR Finder ---\n",
    "# print(\"\\n--- Running Learning Rate Finder ---\")\n",
    "\n",
    "# # 1. Wrap the model\n",
    "# wrapped_model = ModelWrapper(model)\n",
    "\n",
    "# # 2. Define optimizer\n",
    "# optimizer = optim.Adam(wrapped_model.parameters(), lr=1e-7, weight_decay=0.01)\n",
    "\n",
    "# # 3. Wrap the DataLoader\n",
    "# hf_train_iter = HFTrainLoaderIter(train_loader)\n",
    "\n",
    "# # 4. Initialize and run the finder\n",
    "# lr_finder = LRFinder(wrapped_model, optimizer, hf_criterion, device=DEVICE)\n",
    "# lr_finder.range_test(hf_train_iter, end_lr=1, num_iter=100)\n",
    "\n",
    "# # 5. Plot and reset\n",
    "# lr_finder.plot() # Saves lr_finder.png\n",
    "# print(\"LR Finder plot saved to lr_finder.png\")\n",
    "# lr_finder.reset()\n",
    "\n",
    "# print(\"\\n--- LR Finder complete. You can now use the suggested LR for training. ---\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b45690d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7466, 'grad_norm': 1.7839540243148804, 'learning_rate': 9.96964856230032e-05, 'epoch': 0.06389776357827476}\n",
      "{'loss': 2.6081, 'grad_norm': 1.7746158838272095, 'learning_rate': 9.937699680511182e-05, 'epoch': 0.12779552715654952}\n",
      "{'loss': 2.596, 'grad_norm': 1.2530577182769775, 'learning_rate': 9.905750798722045e-05, 'epoch': 0.19169329073482427}\n",
      "{'loss': 2.5844, 'grad_norm': 1.4992753267288208, 'learning_rate': 9.873801916932908e-05, 'epoch': 0.25559105431309903}\n",
      "{'loss': 2.5772, 'grad_norm': 1.730760097503662, 'learning_rate': 9.841853035143771e-05, 'epoch': 0.3194888178913738}\n",
      "{'loss': 2.57, 'grad_norm': 1.6649562120437622, 'learning_rate': 9.809904153354633e-05, 'epoch': 0.38338658146964855}\n",
      "{'loss': 2.5585, 'grad_norm': 1.808052897453308, 'learning_rate': 9.777955271565496e-05, 'epoch': 0.4472843450479233}\n",
      "{'loss': 2.5368, 'grad_norm': 1.4642049074172974, 'learning_rate': 9.746006389776359e-05, 'epoch': 0.5111821086261981}\n",
      "{'loss': 2.4654, 'grad_norm': 1.3726166486740112, 'learning_rate': 9.714057507987221e-05, 'epoch': 0.5750798722044729}\n",
      "{'loss': 2.2889, 'grad_norm': 1.2344876527786255, 'learning_rate': 9.682108626198083e-05, 'epoch': 0.6389776357827476}\n",
      "{'loss': 2.103, 'grad_norm': 1.2018858194351196, 'learning_rate': 9.650159744408947e-05, 'epoch': 0.7028753993610224}\n",
      "{'loss': 1.9899, 'grad_norm': 1.5173206329345703, 'learning_rate': 9.618210862619809e-05, 'epoch': 0.7667731629392971}\n",
      "{'loss': 1.9349, 'grad_norm': 1.2921998500823975, 'learning_rate': 9.586261980830671e-05, 'epoch': 0.8306709265175719}\n",
      "{'loss': 1.9245, 'grad_norm': 1.1663466691970825, 'learning_rate': 9.554313099041534e-05, 'epoch': 0.8945686900958466}\n",
      "{'loss': 1.9032, 'grad_norm': 1.3936750888824463, 'learning_rate': 9.522364217252396e-05, 'epoch': 0.9584664536741214}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 313\n",
      "\n",
      "Evaluating Step 313 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 313 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 313 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0010 (1/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0010 (1/1000)\n",
      "Uniqueness (permutations): 0.0010 (1/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 313 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0370 (37/1000)\n",
      "Representation power: 0.0060 (6/1000)\n",
      "Creativity: 0.0310 (31/1000)\n",
      "Uniqueness (permutations): 0.0370 (37/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 313 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0690 (69/1000)\n",
      "Representation power: 0.0170 (17/1000)\n",
      "Creativity: 0.0510 (51/1000)\n",
      "Uniqueness (permutations): 0.0680 (68/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 313 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0030 (3/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0030 (3/1000)\n",
      "Uniqueness (permutations): 0.0030 (3/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 313\n",
      "New best creativity_mean: 0.0510 (previously -inf)\n",
      "Saving new best model to /datastor1/vansh/lang_sampling/results/circle/M15-N9-H26-NT10000-E20-top_p1.0-attention-only-12/best_models/HL5.pt\n",
      "âœ… Evaluation logged and saved at step 313\n",
      "{'loss': 1.8895, 'grad_norm': 1.1728622913360596, 'learning_rate': 9.490415335463259e-05, 'epoch': 1.0223642172523961}\n",
      "{'loss': 1.8741, 'grad_norm': 1.1353590488433838, 'learning_rate': 9.458466453674121e-05, 'epoch': 1.0862619808306708}\n",
      "{'loss': 1.8744, 'grad_norm': 1.1528924703598022, 'learning_rate': 9.426517571884984e-05, 'epoch': 1.1501597444089458}\n",
      "{'loss': 1.8693, 'grad_norm': 1.093001127243042, 'learning_rate': 9.394568690095847e-05, 'epoch': 1.2140575079872205}\n",
      "{'loss': 1.8602, 'grad_norm': 1.2225254774093628, 'learning_rate': 9.36261980830671e-05, 'epoch': 1.2779552715654952}\n",
      "{'loss': 1.8642, 'grad_norm': 1.3115612268447876, 'learning_rate': 9.330670926517572e-05, 'epoch': 1.34185303514377}\n",
      "{'loss': 1.866, 'grad_norm': 1.0421277284622192, 'learning_rate': 9.298722044728435e-05, 'epoch': 1.4057507987220448}\n",
      "{'loss': 1.8672, 'grad_norm': 1.4504342079162598, 'learning_rate': 9.266773162939297e-05, 'epoch': 1.4696485623003195}\n",
      "{'loss': 1.8585, 'grad_norm': 1.3554614782333374, 'learning_rate': 9.234824281150161e-05, 'epoch': 1.5335463258785942}\n",
      "{'loss': 1.8601, 'grad_norm': 1.1708928346633911, 'learning_rate': 9.202875399361023e-05, 'epoch': 1.5974440894568689}\n",
      "{'loss': 1.8607, 'grad_norm': 1.1321046352386475, 'learning_rate': 9.170926517571885e-05, 'epoch': 1.6613418530351438}\n",
      "{'loss': 1.857, 'grad_norm': 1.4164482355117798, 'learning_rate': 9.138977635782749e-05, 'epoch': 1.7252396166134185}\n",
      "{'loss': 1.8618, 'grad_norm': 1.2868462800979614, 'learning_rate': 9.107028753993611e-05, 'epoch': 1.7891373801916934}\n",
      "{'loss': 1.8571, 'grad_norm': 1.194415807723999, 'learning_rate': 9.075079872204473e-05, 'epoch': 1.8530351437699681}\n",
      "{'loss': 1.8521, 'grad_norm': 1.355456829071045, 'learning_rate': 9.043130990415337e-05, 'epoch': 1.9169329073482428}\n",
      "{'loss': 1.8557, 'grad_norm': 1.2422791719436646, 'learning_rate': 9.011182108626199e-05, 'epoch': 1.9808306709265175}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 626\n",
      "\n",
      "Evaluating Step 626 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 626 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 626 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0090 (9/1000)\n",
      "Representation power: 0.0010 (1/1000)\n",
      "Creativity: 0.0080 (8/1000)\n",
      "Uniqueness (permutations): 0.0090 (9/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 626 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0560 (56/1000)\n",
      "Representation power: 0.0130 (13/1000)\n",
      "Creativity: 0.0430 (43/1000)\n",
      "Uniqueness (permutations): 0.0560 (56/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 626 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0940 (94/1000)\n",
      "Representation power: 0.0170 (17/1000)\n",
      "Creativity: 0.0760 (76/1000)\n",
      "Uniqueness (permutations): 0.0930 (93/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 626 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0190 (19/1000)\n",
      "Representation power: 0.0030 (3/1000)\n",
      "Creativity: 0.0160 (16/1000)\n",
      "Uniqueness (permutations): 0.0190 (19/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 626\n",
      "New best creativity_mean: 0.0760 (previously 0.0510)\n",
      "Saving new best model to /datastor1/vansh/lang_sampling/results/circle/M15-N9-H26-NT10000-E20-top_p1.0-attention-only-12/best_models/HL5.pt\n",
      "âœ… Evaluation logged and saved at step 626\n",
      "{'loss': 1.8201, 'grad_norm': 1.3994882106781006, 'learning_rate': 8.979233226837061e-05, 'epoch': 2.0447284345047922}\n",
      "{'loss': 1.8034, 'grad_norm': 1.363571047782898, 'learning_rate': 8.947284345047923e-05, 'epoch': 2.108626198083067}\n",
      "{'loss': 1.8054, 'grad_norm': 1.326202154159546, 'learning_rate': 8.915335463258785e-05, 'epoch': 2.1725239616613417}\n",
      "{'loss': 1.8064, 'grad_norm': 1.244869351387024, 'learning_rate': 8.883386581469649e-05, 'epoch': 2.236421725239617}\n",
      "{'loss': 1.8133, 'grad_norm': 1.0553783178329468, 'learning_rate': 8.851437699680511e-05, 'epoch': 2.3003194888178915}\n",
      "{'loss': 1.8125, 'grad_norm': 1.1759225130081177, 'learning_rate': 8.819488817891373e-05, 'epoch': 2.364217252396166}\n",
      "{'loss': 1.8106, 'grad_norm': 1.3678576946258545, 'learning_rate': 8.787539936102237e-05, 'epoch': 2.428115015974441}\n",
      "{'loss': 1.8166, 'grad_norm': 1.279453992843628, 'learning_rate': 8.755591054313099e-05, 'epoch': 2.4920127795527156}\n",
      "{'loss': 1.8131, 'grad_norm': 1.354439616203308, 'learning_rate': 8.723642172523963e-05, 'epoch': 2.5559105431309903}\n",
      "{'loss': 1.8162, 'grad_norm': 1.1000720262527466, 'learning_rate': 8.691693290734825e-05, 'epoch': 2.619808306709265}\n",
      "{'loss': 1.8147, 'grad_norm': 1.3522250652313232, 'learning_rate': 8.659744408945687e-05, 'epoch': 2.68370607028754}\n",
      "{'loss': 1.823, 'grad_norm': 1.2435137033462524, 'learning_rate': 8.62779552715655e-05, 'epoch': 2.747603833865815}\n",
      "{'loss': 1.8183, 'grad_norm': 1.4359326362609863, 'learning_rate': 8.595846645367413e-05, 'epoch': 2.8115015974440896}\n",
      "{'loss': 1.8144, 'grad_norm': 1.4011166095733643, 'learning_rate': 8.563897763578275e-05, 'epoch': 2.8753993610223643}\n",
      "{'loss': 1.8066, 'grad_norm': 1.1238564252853394, 'learning_rate': 8.531948881789138e-05, 'epoch': 2.939297124600639}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 939\n",
      "\n",
      "Evaluating Step 939 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 939 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0060 (6/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0060 (6/1000)\n",
      "Uniqueness (permutations): 0.0060 (6/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 939 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0420 (42/1000)\n",
      "Representation power: 0.0080 (8/1000)\n",
      "Creativity: 0.0330 (33/1000)\n",
      "Uniqueness (permutations): 0.0410 (41/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 939 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1190 (119/1000)\n",
      "Representation power: 0.0240 (24/1000)\n",
      "Creativity: 0.0950 (95/1000)\n",
      "Uniqueness (permutations): 0.1190 (119/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 939 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1590 (159/1000)\n",
      "Representation power: 0.0300 (30/1000)\n",
      "Creativity: 0.1290 (129/1000)\n",
      "Uniqueness (permutations): 0.1590 (159/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 939 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0260 (26/1000)\n",
      "Representation power: 0.0080 (8/1000)\n",
      "Creativity: 0.0180 (18/1000)\n",
      "Uniqueness (permutations): 0.0260 (26/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 939\n",
      "New best creativity_mean: 0.1290 (previously 0.0760)\n",
      "Saving new best model to /datastor1/vansh/lang_sampling/results/circle/M15-N9-H26-NT10000-E20-top_p1.0-attention-only-12/best_models/HL5.pt\n",
      "âœ… Evaluation logged and saved at step 939\n",
      "{'loss': 1.8011, 'grad_norm': 1.079982876777649, 'learning_rate': 8.5e-05, 'epoch': 3.0031948881789137}\n",
      "{'loss': 1.7626, 'grad_norm': 1.3975250720977783, 'learning_rate': 8.468051118210864e-05, 'epoch': 3.0670926517571884}\n",
      "{'loss': 1.7597, 'grad_norm': 1.2801498174667358, 'learning_rate': 8.436102236421726e-05, 'epoch': 3.130990415335463}\n",
      "{'loss': 1.7629, 'grad_norm': 1.3156670331954956, 'learning_rate': 8.404153354632589e-05, 'epoch': 3.194888178913738}\n",
      "{'loss': 1.7595, 'grad_norm': 1.3780219554901123, 'learning_rate': 8.372204472843451e-05, 'epoch': 3.258785942492013}\n",
      "{'loss': 1.7688, 'grad_norm': 1.215727686882019, 'learning_rate': 8.340255591054313e-05, 'epoch': 3.3226837060702876}\n",
      "{'loss': 1.7667, 'grad_norm': 1.2512786388397217, 'learning_rate': 8.308306709265175e-05, 'epoch': 3.3865814696485623}\n",
      "{'loss': 1.7723, 'grad_norm': 1.2564373016357422, 'learning_rate': 8.276357827476039e-05, 'epoch': 3.450479233226837}\n",
      "{'loss': 1.7745, 'grad_norm': 1.172332763671875, 'learning_rate': 8.244408945686901e-05, 'epoch': 3.5143769968051117}\n",
      "{'loss': 1.7789, 'grad_norm': 1.3589835166931152, 'learning_rate': 8.212460063897764e-05, 'epoch': 3.5782747603833864}\n",
      "{'loss': 1.767, 'grad_norm': 1.4308120012283325, 'learning_rate': 8.180511182108627e-05, 'epoch': 3.642172523961661}\n",
      "{'loss': 1.7742, 'grad_norm': 1.3306326866149902, 'learning_rate': 8.148562300319489e-05, 'epoch': 3.7060702875399363}\n",
      "{'loss': 1.7711, 'grad_norm': 1.1200536489486694, 'learning_rate': 8.116613418530352e-05, 'epoch': 3.769968051118211}\n",
      "{'loss': 1.7721, 'grad_norm': 1.2058428525924683, 'learning_rate': 8.084664536741214e-05, 'epoch': 3.8338658146964857}\n",
      "{'loss': 1.7745, 'grad_norm': 1.1596167087554932, 'learning_rate': 8.052715654952077e-05, 'epoch': 3.8977635782747604}\n",
      "{'loss': 1.7783, 'grad_norm': 1.2088587284088135, 'learning_rate': 8.02076677316294e-05, 'epoch': 3.961661341853035}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 1252\n",
      "\n",
      "Evaluating Step 1252 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 1252 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0380 (38/1000)\n",
      "Representation power: 0.0060 (6/1000)\n",
      "Creativity: 0.0260 (26/1000)\n",
      "Uniqueness (permutations): 0.0320 (32/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 1252 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0860 (86/1000)\n",
      "Representation power: 0.0150 (15/1000)\n",
      "Creativity: 0.0700 (70/1000)\n",
      "Uniqueness (permutations): 0.0850 (85/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 1252 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1520 (152/1000)\n",
      "Representation power: 0.0380 (38/1000)\n",
      "Creativity: 0.1140 (114/1000)\n",
      "Uniqueness (permutations): 0.1520 (152/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 1252 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1710 (171/1000)\n",
      "Representation power: 0.0260 (26/1000)\n",
      "Creativity: 0.1450 (145/1000)\n",
      "Uniqueness (permutations): 0.1710 (171/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 1252 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0330 (33/1000)\n",
      "Representation power: 0.0070 (7/1000)\n",
      "Creativity: 0.0260 (26/1000)\n",
      "Uniqueness (permutations): 0.0330 (33/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 1252\n",
      "New best creativity_mean: 0.1450 (previously 0.1290)\n",
      "Saving new best model to /datastor1/vansh/lang_sampling/results/circle/M15-N9-H26-NT10000-E20-top_p1.0-attention-only-12/best_models/HL5.pt\n",
      "âœ… Evaluation logged and saved at step 1252\n",
      "{'loss': 1.7573, 'grad_norm': 1.233932375907898, 'learning_rate': 7.988817891373802e-05, 'epoch': 4.02555910543131}\n",
      "{'loss': 1.7086, 'grad_norm': 1.3707005977630615, 'learning_rate': 7.956869009584666e-05, 'epoch': 4.0894568690095845}\n",
      "{'loss': 1.7088, 'grad_norm': 1.3930829763412476, 'learning_rate': 7.924920127795528e-05, 'epoch': 4.15335463258786}\n",
      "{'loss': 1.7096, 'grad_norm': 1.197929859161377, 'learning_rate': 7.89297124600639e-05, 'epoch': 4.217252396166134}\n",
      "{'loss': 1.719, 'grad_norm': 1.219353199005127, 'learning_rate': 7.861022364217254e-05, 'epoch': 4.281150159744409}\n",
      "{'loss': 1.7219, 'grad_norm': 1.5300134420394897, 'learning_rate': 7.829073482428116e-05, 'epoch': 4.345047923322683}\n",
      "{'loss': 1.7207, 'grad_norm': 1.2421849966049194, 'learning_rate': 7.797124600638978e-05, 'epoch': 4.4089456869009584}\n",
      "{'loss': 1.7256, 'grad_norm': 1.5432230234146118, 'learning_rate': 7.76517571884984e-05, 'epoch': 4.472843450479234}\n",
      "{'loss': 1.7234, 'grad_norm': 1.1826210021972656, 'learning_rate': 7.733226837060703e-05, 'epoch': 4.536741214057508}\n",
      "{'loss': 1.732, 'grad_norm': 1.2927451133728027, 'learning_rate': 7.701277955271566e-05, 'epoch': 4.600638977635783}\n",
      "{'loss': 1.7352, 'grad_norm': 1.154737949371338, 'learning_rate': 7.669329073482428e-05, 'epoch': 4.664536741214057}\n",
      "{'loss': 1.7334, 'grad_norm': 1.206526279449463, 'learning_rate': 7.63738019169329e-05, 'epoch': 4.728434504792332}\n",
      "{'loss': 1.7339, 'grad_norm': 1.3113399744033813, 'learning_rate': 7.605431309904154e-05, 'epoch': 4.792332268370607}\n",
      "{'loss': 1.7338, 'grad_norm': 1.1643832921981812, 'learning_rate': 7.573482428115016e-05, 'epoch': 4.856230031948882}\n",
      "{'loss': 1.7382, 'grad_norm': 1.1980348825454712, 'learning_rate': 7.541533546325878e-05, 'epoch': 4.920127795527156}\n",
      "{'loss': 1.7312, 'grad_norm': 1.533282995223999, 'learning_rate': 7.509584664536742e-05, 'epoch': 4.984025559105431}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 1565\n",
      "\n",
      "Evaluating Step 1565 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 1565 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0530 (53/1000)\n",
      "Representation power: 0.0080 (8/1000)\n",
      "Creativity: 0.0370 (37/1000)\n",
      "Uniqueness (permutations): 0.0450 (45/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 1565 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1020 (102/1000)\n",
      "Representation power: 0.0310 (31/1000)\n",
      "Creativity: 0.0680 (68/1000)\n",
      "Uniqueness (permutations): 0.0990 (99/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 1565 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1610 (161/1000)\n",
      "Representation power: 0.0300 (30/1000)\n",
      "Creativity: 0.1300 (130/1000)\n",
      "Uniqueness (permutations): 0.1600 (160/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 1565 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1810 (181/1000)\n",
      "Representation power: 0.0340 (34/1000)\n",
      "Creativity: 0.1450 (145/1000)\n",
      "Uniqueness (permutations): 0.1790 (179/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 1565 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0380 (38/1000)\n",
      "Representation power: 0.0080 (8/1000)\n",
      "Creativity: 0.0300 (30/1000)\n",
      "Uniqueness (permutations): 0.0380 (38/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 1565\n",
      "âœ… Evaluation logged and saved at step 1565\n",
      "{'loss': 1.6743, 'grad_norm': 1.3226865530014038, 'learning_rate': 7.477635782747604e-05, 'epoch': 5.047923322683706}\n",
      "{'loss': 1.6685, 'grad_norm': 1.250612735748291, 'learning_rate': 7.445686900958468e-05, 'epoch': 5.111821086261981}\n",
      "{'loss': 1.6535, 'grad_norm': 1.366550326347351, 'learning_rate': 7.41373801916933e-05, 'epoch': 5.175718849840256}\n",
      "{'loss': 1.6516, 'grad_norm': 1.2944751977920532, 'learning_rate': 7.381789137380192e-05, 'epoch': 5.23961661341853}\n",
      "{'loss': 1.6708, 'grad_norm': 1.4400304555892944, 'learning_rate': 7.349840255591056e-05, 'epoch': 5.303514376996805}\n",
      "{'loss': 1.6716, 'grad_norm': 1.3719251155853271, 'learning_rate': 7.317891373801918e-05, 'epoch': 5.36741214057508}\n",
      "{'loss': 1.6701, 'grad_norm': 1.2414436340332031, 'learning_rate': 7.28594249201278e-05, 'epoch': 5.431309904153355}\n",
      "{'loss': 1.6798, 'grad_norm': 1.3024563789367676, 'learning_rate': 7.253993610223642e-05, 'epoch': 5.49520766773163}\n",
      "{'loss': 1.6881, 'grad_norm': 1.389451265335083, 'learning_rate': 7.222044728434506e-05, 'epoch': 5.559105431309904}\n",
      "{'loss': 1.6861, 'grad_norm': 1.3701380491256714, 'learning_rate': 7.190095846645368e-05, 'epoch': 5.623003194888179}\n",
      "{'loss': 1.676, 'grad_norm': 1.2671507596969604, 'learning_rate': 7.15814696485623e-05, 'epoch': 5.686900958466453}\n",
      "{'loss': 1.6845, 'grad_norm': 1.3011473417282104, 'learning_rate': 7.126198083067092e-05, 'epoch': 5.7507987220447285}\n",
      "{'loss': 1.6861, 'grad_norm': 1.2912498712539673, 'learning_rate': 7.094249201277956e-05, 'epoch': 5.814696485623003}\n",
      "{'loss': 1.6846, 'grad_norm': 1.3098400831222534, 'learning_rate': 7.062300319488818e-05, 'epoch': 5.878594249201278}\n",
      "{'loss': 1.6916, 'grad_norm': 1.3564637899398804, 'learning_rate': 7.03035143769968e-05, 'epoch': 5.942492012779553}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 1878\n",
      "\n",
      "Evaluating Step 1878 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 1878 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0640 (64/1000)\n",
      "Representation power: 0.0150 (15/1000)\n",
      "Creativity: 0.0390 (39/1000)\n",
      "Uniqueness (permutations): 0.0540 (54/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 1878 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0940 (94/1000)\n",
      "Representation power: 0.0190 (19/1000)\n",
      "Creativity: 0.0700 (70/1000)\n",
      "Uniqueness (permutations): 0.0890 (89/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 1878 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1670 (167/1000)\n",
      "Representation power: 0.0420 (42/1000)\n",
      "Creativity: 0.1230 (123/1000)\n",
      "Uniqueness (permutations): 0.1650 (165/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 1878 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2100 (210/1000)\n",
      "Representation power: 0.0380 (38/1000)\n",
      "Creativity: 0.1710 (171/1000)\n",
      "Uniqueness (permutations): 0.2090 (209/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 1878 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0470 (47/1000)\n",
      "Representation power: 0.0120 (12/1000)\n",
      "Creativity: 0.0350 (35/1000)\n",
      "Uniqueness (permutations): 0.0470 (47/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 1878\n",
      "New best creativity_mean: 0.1710 (previously 0.1450)\n",
      "Saving new best model to /datastor1/vansh/lang_sampling/results/circle/M15-N9-H26-NT10000-E20-top_p1.0-attention-only-12/best_models/HL5.pt\n",
      "âœ… Evaluation logged and saved at step 1878\n",
      "{'loss': 1.6848, 'grad_norm': 1.3009638786315918, 'learning_rate': 6.998402555910544e-05, 'epoch': 6.006389776357827}\n",
      "{'loss': 1.5969, 'grad_norm': 1.4271448850631714, 'learning_rate': 6.966453674121406e-05, 'epoch': 6.0702875399361025}\n",
      "{'loss': 1.5986, 'grad_norm': 1.4470738172531128, 'learning_rate': 6.93450479233227e-05, 'epoch': 6.134185303514377}\n",
      "{'loss': 1.6089, 'grad_norm': 1.4279714822769165, 'learning_rate': 6.902555910543132e-05, 'epoch': 6.198083067092652}\n",
      "{'loss': 1.6097, 'grad_norm': 1.353945255279541, 'learning_rate': 6.870607028753994e-05, 'epoch': 6.261980830670926}\n",
      "{'loss': 1.6205, 'grad_norm': 1.4607030153274536, 'learning_rate': 6.838658146964857e-05, 'epoch': 6.325878594249201}\n",
      "{'loss': 1.6147, 'grad_norm': 1.2714329957962036, 'learning_rate': 6.80670926517572e-05, 'epoch': 6.389776357827476}\n",
      "{'loss': 1.6235, 'grad_norm': 1.335410475730896, 'learning_rate': 6.774760383386582e-05, 'epoch': 6.453674121405751}\n",
      "{'loss': 1.6201, 'grad_norm': 1.2899246215820312, 'learning_rate': 6.742811501597445e-05, 'epoch': 6.517571884984026}\n",
      "{'loss': 1.6393, 'grad_norm': 1.393507719039917, 'learning_rate': 6.710862619808307e-05, 'epoch': 6.5814696485623}\n",
      "{'loss': 1.628, 'grad_norm': 1.4595050811767578, 'learning_rate': 6.67891373801917e-05, 'epoch': 6.645367412140575}\n",
      "{'loss': 1.6424, 'grad_norm': 1.4358798265457153, 'learning_rate': 6.646964856230032e-05, 'epoch': 6.7092651757188495}\n",
      "{'loss': 1.6359, 'grad_norm': 1.4115442037582397, 'learning_rate': 6.615015974440894e-05, 'epoch': 6.773162939297125}\n",
      "{'loss': 1.6396, 'grad_norm': 1.3857650756835938, 'learning_rate': 6.583067092651757e-05, 'epoch': 6.8370607028754}\n",
      "{'loss': 1.6322, 'grad_norm': 1.3427495956420898, 'learning_rate': 6.55111821086262e-05, 'epoch': 6.900958466453674}\n",
      "{'loss': 1.6333, 'grad_norm': 1.4041391611099243, 'learning_rate': 6.519169329073482e-05, 'epoch': 6.964856230031949}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 2191\n",
      "\n",
      "Evaluating Step 2191 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 2191 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0930 (93/1000)\n",
      "Representation power: 0.0130 (13/1000)\n",
      "Creativity: 0.0680 (68/1000)\n",
      "Uniqueness (permutations): 0.0810 (81/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 2191 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1450 (145/1000)\n",
      "Representation power: 0.0280 (28/1000)\n",
      "Creativity: 0.1140 (114/1000)\n",
      "Uniqueness (permutations): 0.1420 (142/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 2191 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1840 (184/1000)\n",
      "Representation power: 0.0400 (40/1000)\n",
      "Creativity: 0.1420 (142/1000)\n",
      "Uniqueness (permutations): 0.1820 (182/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 2191 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2160 (216/1000)\n",
      "Representation power: 0.0480 (48/1000)\n",
      "Creativity: 0.1670 (167/1000)\n",
      "Uniqueness (permutations): 0.2150 (215/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 2191 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0690 (69/1000)\n",
      "Representation power: 0.0190 (19/1000)\n",
      "Creativity: 0.0500 (50/1000)\n",
      "Uniqueness (permutations): 0.0690 (69/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 2191\n",
      "âœ… Evaluation logged and saved at step 2191\n",
      "{'loss': 1.5896, 'grad_norm': 1.5068358182907104, 'learning_rate': 6.487220447284345e-05, 'epoch': 7.0287539936102235}\n",
      "{'loss': 1.5339, 'grad_norm': 1.4728292226791382, 'learning_rate': 6.455271565495208e-05, 'epoch': 7.092651757188499}\n",
      "{'loss': 1.5399, 'grad_norm': 1.4464738368988037, 'learning_rate': 6.42332268370607e-05, 'epoch': 7.156549520766773}\n",
      "{'loss': 1.5496, 'grad_norm': 1.4729915857315063, 'learning_rate': 6.391373801916933e-05, 'epoch': 7.220447284345048}\n",
      "{'loss': 1.5577, 'grad_norm': 1.4895175695419312, 'learning_rate': 6.359424920127795e-05, 'epoch': 7.284345047923322}\n",
      "{'loss': 1.5536, 'grad_norm': 1.472372055053711, 'learning_rate': 6.327476038338659e-05, 'epoch': 7.348242811501597}\n",
      "{'loss': 1.5577, 'grad_norm': 1.4131028652191162, 'learning_rate': 6.295527156549521e-05, 'epoch': 7.412140575079873}\n",
      "{'loss': 1.5714, 'grad_norm': 1.4262031316757202, 'learning_rate': 6.263578274760383e-05, 'epoch': 7.476038338658147}\n",
      "{'loss': 1.5783, 'grad_norm': 1.4414328336715698, 'learning_rate': 6.231629392971247e-05, 'epoch': 7.539936102236422}\n",
      "{'loss': 1.5692, 'grad_norm': 1.4254491329193115, 'learning_rate': 6.199680511182109e-05, 'epoch': 7.603833865814696}\n",
      "{'loss': 1.5647, 'grad_norm': 1.5968025922775269, 'learning_rate': 6.167731629392971e-05, 'epoch': 7.667731629392971}\n",
      "{'loss': 1.5766, 'grad_norm': 1.4010202884674072, 'learning_rate': 6.135782747603835e-05, 'epoch': 7.731629392971246}\n",
      "{'loss': 1.5759, 'grad_norm': 1.503159523010254, 'learning_rate': 6.103833865814697e-05, 'epoch': 7.795527156549521}\n",
      "{'loss': 1.579, 'grad_norm': 1.4937902688980103, 'learning_rate': 6.07188498402556e-05, 'epoch': 7.859424920127795}\n",
      "{'loss': 1.584, 'grad_norm': 1.5939741134643555, 'learning_rate': 6.039936102236422e-05, 'epoch': 7.92332268370607}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5891, 'grad_norm': 1.505344033241272, 'learning_rate': 6.007987220447284e-05, 'epoch': 7.987220447284345}\n",
      "\n",
      "ðŸ“ˆ Live evaluation at step 2504\n",
      "\n",
      "Evaluating Step 2504 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 2504 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1460 (146/1000)\n",
      "Representation power: 0.0270 (27/1000)\n",
      "Creativity: 0.1090 (109/1000)\n",
      "Uniqueness (permutations): 0.1360 (136/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 2504 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1710 (171/1000)\n",
      "Representation power: 0.0380 (38/1000)\n",
      "Creativity: 0.1280 (128/1000)\n",
      "Uniqueness (permutations): 0.1660 (166/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 2504 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2260 (226/1000)\n",
      "Representation power: 0.0380 (38/1000)\n",
      "Creativity: 0.1860 (186/1000)\n",
      "Uniqueness (permutations): 0.2240 (224/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 2504 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2290 (229/1000)\n",
      "Representation power: 0.0570 (57/1000)\n",
      "Creativity: 0.1710 (171/1000)\n",
      "Uniqueness (permutations): 0.2280 (228/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 2504 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0750 (75/1000)\n",
      "Representation power: 0.0130 (13/1000)\n",
      "Creativity: 0.0620 (62/1000)\n",
      "Uniqueness (permutations): 0.0750 (75/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 2504\n",
      "New best creativity_mean: 0.1860 (previously 0.1710)\n",
      "Saving new best model to /datastor1/vansh/lang_sampling/results/circle/M15-N9-H26-NT10000-E20-top_p1.0-attention-only-12/best_models/HL5.pt\n",
      "âœ… Evaluation logged and saved at step 2504\n",
      "{'loss': 1.4947, 'grad_norm': 1.3900750875473022, 'learning_rate': 5.976038338658148e-05, 'epoch': 8.05111821086262}\n",
      "{'loss': 1.4839, 'grad_norm': 1.4431532621383667, 'learning_rate': 5.94408945686901e-05, 'epoch': 8.115015974440894}\n",
      "{'loss': 1.4941, 'grad_norm': 1.4076553583145142, 'learning_rate': 5.912140575079872e-05, 'epoch': 8.178913738019169}\n",
      "{'loss': 1.4939, 'grad_norm': 1.5879098176956177, 'learning_rate': 5.880191693290735e-05, 'epoch': 8.242811501597444}\n",
      "{'loss': 1.4989, 'grad_norm': 1.547208547592163, 'learning_rate': 5.848242811501597e-05, 'epoch': 8.30670926517572}\n",
      "{'loss': 1.4948, 'grad_norm': 1.4947642087936401, 'learning_rate': 5.816293929712461e-05, 'epoch': 8.370607028753994}\n",
      "{'loss': 1.5077, 'grad_norm': 1.449532389640808, 'learning_rate': 5.784345047923323e-05, 'epoch': 8.434504792332268}\n",
      "{'loss': 1.5067, 'grad_norm': 1.502628207206726, 'learning_rate': 5.752396166134185e-05, 'epoch': 8.498402555910543}\n",
      "{'loss': 1.5061, 'grad_norm': 1.5496371984481812, 'learning_rate': 5.720447284345049e-05, 'epoch': 8.562300319488818}\n",
      "{'loss': 1.5186, 'grad_norm': 1.6490992307662964, 'learning_rate': 5.688498402555911e-05, 'epoch': 8.626198083067093}\n",
      "{'loss': 1.5189, 'grad_norm': 1.5774656534194946, 'learning_rate': 5.656549520766773e-05, 'epoch': 8.690095846645367}\n",
      "{'loss': 1.5236, 'grad_norm': 1.468072533607483, 'learning_rate': 5.624600638977636e-05, 'epoch': 8.753993610223642}\n",
      "{'loss': 1.5306, 'grad_norm': 1.6216182708740234, 'learning_rate': 5.592651757188498e-05, 'epoch': 8.817891373801917}\n",
      "{'loss': 1.527, 'grad_norm': 1.6014158725738525, 'learning_rate': 5.5607028753993616e-05, 'epoch': 8.881789137380192}\n",
      "{'loss': 1.53, 'grad_norm': 1.5523275136947632, 'learning_rate': 5.528753993610224e-05, 'epoch': 8.945686900958467}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 2817\n",
      "\n",
      "Evaluating Step 2817 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 2817 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1480 (148/1000)\n",
      "Representation power: 0.0360 (36/1000)\n",
      "Creativity: 0.1060 (106/1000)\n",
      "Uniqueness (permutations): 0.1420 (142/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 2817 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1770 (177/1000)\n",
      "Representation power: 0.0310 (31/1000)\n",
      "Creativity: 0.1460 (146/1000)\n",
      "Uniqueness (permutations): 0.1770 (177/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 2817 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2040 (204/1000)\n",
      "Representation power: 0.0510 (51/1000)\n",
      "Creativity: 0.1500 (150/1000)\n",
      "Uniqueness (permutations): 0.2010 (201/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 2817 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2360 (236/1000)\n",
      "Representation power: 0.0540 (54/1000)\n",
      "Creativity: 0.1800 (180/1000)\n",
      "Uniqueness (permutations): 0.2340 (234/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 2817 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0730 (73/1000)\n",
      "Representation power: 0.0140 (14/1000)\n",
      "Creativity: 0.0590 (59/1000)\n",
      "Uniqueness (permutations): 0.0730 (73/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 2817\n",
      "âœ… Evaluation logged and saved at step 2817\n",
      "{'loss': 1.5172, 'grad_norm': 1.4047764539718628, 'learning_rate': 5.496805111821086e-05, 'epoch': 9.00958466453674}\n",
      "{'loss': 1.4255, 'grad_norm': 1.4815504550933838, 'learning_rate': 5.4648562300319495e-05, 'epoch': 9.073482428115016}\n",
      "{'loss': 1.4307, 'grad_norm': 1.670992374420166, 'learning_rate': 5.432907348242812e-05, 'epoch': 9.13738019169329}\n",
      "{'loss': 1.4355, 'grad_norm': 1.5415964126586914, 'learning_rate': 5.400958466453674e-05, 'epoch': 9.201277955271566}\n",
      "{'loss': 1.4335, 'grad_norm': 1.7118699550628662, 'learning_rate': 5.3690095846645375e-05, 'epoch': 9.26517571884984}\n",
      "{'loss': 1.4399, 'grad_norm': 1.6285300254821777, 'learning_rate': 5.3370607028753996e-05, 'epoch': 9.329073482428115}\n",
      "{'loss': 1.447, 'grad_norm': 1.5937308073043823, 'learning_rate': 5.3051118210862625e-05, 'epoch': 9.39297124600639}\n",
      "{'loss': 1.4472, 'grad_norm': 1.541239619255066, 'learning_rate': 5.273162939297125e-05, 'epoch': 9.456869009584665}\n",
      "{'loss': 1.4599, 'grad_norm': 1.6592806577682495, 'learning_rate': 5.241214057507987e-05, 'epoch': 9.52076677316294}\n",
      "{'loss': 1.4595, 'grad_norm': 1.5374484062194824, 'learning_rate': 5.2092651757188504e-05, 'epoch': 9.584664536741213}\n",
      "{'loss': 1.4701, 'grad_norm': 1.6624749898910522, 'learning_rate': 5.1773162939297126e-05, 'epoch': 9.648562300319488}\n",
      "{'loss': 1.4686, 'grad_norm': 1.6658902168273926, 'learning_rate': 5.145367412140575e-05, 'epoch': 9.712460063897764}\n",
      "{'loss': 1.4717, 'grad_norm': 1.5462074279785156, 'learning_rate': 5.113418530351438e-05, 'epoch': 9.776357827476039}\n",
      "{'loss': 1.4748, 'grad_norm': 1.6432781219482422, 'learning_rate': 5.0814696485623005e-05, 'epoch': 9.840255591054314}\n",
      "{'loss': 1.474, 'grad_norm': 1.5632352828979492, 'learning_rate': 5.0495207667731634e-05, 'epoch': 9.904153354632587}\n",
      "{'loss': 1.4756, 'grad_norm': 1.5661499500274658, 'learning_rate': 5.0175718849840256e-05, 'epoch': 9.968051118210862}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 3130\n",
      "\n",
      "Evaluating Step 3130 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 3130 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1610 (161/1000)\n",
      "Representation power: 0.0410 (41/1000)\n",
      "Creativity: 0.1160 (116/1000)\n",
      "Uniqueness (permutations): 0.1570 (157/1000)\n",
      "Uniqueness (strings): 0.9980 (998/1000)\n",
      "\n",
      "Evaluating Step 3130 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1830 (183/1000)\n",
      "Representation power: 0.0370 (37/1000)\n",
      "Creativity: 0.1430 (143/1000)\n",
      "Uniqueness (permutations): 0.1800 (180/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 3130 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2160 (216/1000)\n",
      "Representation power: 0.0530 (53/1000)\n",
      "Creativity: 0.1610 (161/1000)\n",
      "Uniqueness (permutations): 0.2140 (214/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 3130 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2380 (238/1000)\n",
      "Representation power: 0.0560 (56/1000)\n",
      "Creativity: 0.1820 (182/1000)\n",
      "Uniqueness (permutations): 0.2380 (238/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 3130 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0990 (99/1000)\n",
      "Representation power: 0.0230 (23/1000)\n",
      "Creativity: 0.0760 (76/1000)\n",
      "Uniqueness (permutations): 0.0990 (99/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 3130\n",
      "âœ… Evaluation logged and saved at step 3130\n",
      "{'loss': 1.4278, 'grad_norm': 1.6277681589126587, 'learning_rate': 4.9856230031948884e-05, 'epoch': 10.031948881789138}\n",
      "{'loss': 1.3659, 'grad_norm': 1.5536680221557617, 'learning_rate': 4.9536741214057506e-05, 'epoch': 10.095846645367413}\n",
      "{'loss': 1.3823, 'grad_norm': 1.6118841171264648, 'learning_rate': 4.9217252396166135e-05, 'epoch': 10.159744408945686}\n",
      "{'loss': 1.391, 'grad_norm': 1.7030630111694336, 'learning_rate': 4.889776357827476e-05, 'epoch': 10.223642172523961}\n",
      "{'loss': 1.3855, 'grad_norm': 1.7242953777313232, 'learning_rate': 4.857827476038339e-05, 'epoch': 10.287539936102236}\n",
      "{'loss': 1.3937, 'grad_norm': 1.6250646114349365, 'learning_rate': 4.8258785942492014e-05, 'epoch': 10.351437699680512}\n",
      "{'loss': 1.3934, 'grad_norm': 1.6267012357711792, 'learning_rate': 4.793929712460064e-05, 'epoch': 10.415335463258787}\n",
      "{'loss': 1.3997, 'grad_norm': 1.6521084308624268, 'learning_rate': 4.761980830670927e-05, 'epoch': 10.47923322683706}\n",
      "{'loss': 1.3956, 'grad_norm': 1.704013466835022, 'learning_rate': 4.730031948881789e-05, 'epoch': 10.543130990415335}\n",
      "{'loss': 1.4038, 'grad_norm': 1.7721017599105835, 'learning_rate': 4.6980830670926515e-05, 'epoch': 10.60702875399361}\n",
      "{'loss': 1.4213, 'grad_norm': 1.6358693838119507, 'learning_rate': 4.6661341853035143e-05, 'epoch': 10.670926517571885}\n",
      "{'loss': 1.4074, 'grad_norm': 1.7173335552215576, 'learning_rate': 4.634185303514377e-05, 'epoch': 10.73482428115016}\n",
      "{'loss': 1.4016, 'grad_norm': 1.7005690336227417, 'learning_rate': 4.60223642172524e-05, 'epoch': 10.798722044728434}\n",
      "{'loss': 1.4214, 'grad_norm': 1.666659951210022, 'learning_rate': 4.570287539936102e-05, 'epoch': 10.86261980830671}\n",
      "{'loss': 1.4259, 'grad_norm': 1.855823278427124, 'learning_rate': 4.538338658146965e-05, 'epoch': 10.926517571884984}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4281, 'grad_norm': 1.6730287075042725, 'learning_rate': 4.506389776357828e-05, 'epoch': 10.99041533546326}\n",
      "\n",
      "ðŸ“ˆ Live evaluation at step 3443\n",
      "\n",
      "Evaluating Step 3443 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 3443 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1340 (134/1000)\n",
      "Representation power: 0.0280 (28/1000)\n",
      "Creativity: 0.1010 (101/1000)\n",
      "Uniqueness (permutations): 0.1290 (129/1000)\n",
      "Uniqueness (strings): 0.9980 (998/1000)\n",
      "\n",
      "Evaluating Step 3443 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1650 (165/1000)\n",
      "Representation power: 0.0330 (33/1000)\n",
      "Creativity: 0.1280 (128/1000)\n",
      "Uniqueness (permutations): 0.1610 (161/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 3443 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1900 (190/1000)\n",
      "Representation power: 0.0360 (36/1000)\n",
      "Creativity: 0.1510 (151/1000)\n",
      "Uniqueness (permutations): 0.1870 (187/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 3443 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2090 (209/1000)\n",
      "Representation power: 0.0520 (52/1000)\n",
      "Creativity: 0.1570 (157/1000)\n",
      "Uniqueness (permutations): 0.2090 (209/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 3443 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.0990 (99/1000)\n",
      "Representation power: 0.0270 (27/1000)\n",
      "Creativity: 0.0720 (72/1000)\n",
      "Uniqueness (permutations): 0.0990 (99/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 3443\n",
      "âœ… Evaluation logged and saved at step 3443\n",
      "{'loss': 1.3348, 'grad_norm': 1.7136598825454712, 'learning_rate': 4.474440894568691e-05, 'epoch': 11.054313099041533}\n",
      "{'loss': 1.3256, 'grad_norm': 1.5526137351989746, 'learning_rate': 4.442492012779553e-05, 'epoch': 11.118210862619808}\n",
      "{'loss': 1.3303, 'grad_norm': 1.5580222606658936, 'learning_rate': 4.410543130990415e-05, 'epoch': 11.182108626198083}\n",
      "{'loss': 1.3346, 'grad_norm': 1.6514261960983276, 'learning_rate': 4.378594249201278e-05, 'epoch': 11.246006389776358}\n",
      "{'loss': 1.3451, 'grad_norm': 1.7399109601974487, 'learning_rate': 4.346645367412141e-05, 'epoch': 11.309904153354633}\n",
      "{'loss': 1.362, 'grad_norm': 1.733844518661499, 'learning_rate': 4.314696485623003e-05, 'epoch': 11.373801916932907}\n",
      "{'loss': 1.3559, 'grad_norm': 1.7616972923278809, 'learning_rate': 4.282747603833866e-05, 'epoch': 11.437699680511182}\n",
      "{'loss': 1.3497, 'grad_norm': 1.7560434341430664, 'learning_rate': 4.250798722044729e-05, 'epoch': 11.501597444089457}\n",
      "{'loss': 1.3546, 'grad_norm': 1.7550357580184937, 'learning_rate': 4.218849840255592e-05, 'epoch': 11.565495207667732}\n",
      "{'loss': 1.3589, 'grad_norm': 1.75824773311615, 'learning_rate': 4.186900958466454e-05, 'epoch': 11.629392971246006}\n",
      "{'loss': 1.3558, 'grad_norm': 1.7164520025253296, 'learning_rate': 4.154952076677317e-05, 'epoch': 11.69329073482428}\n",
      "{'loss': 1.3544, 'grad_norm': 1.648415446281433, 'learning_rate': 4.123003194888179e-05, 'epoch': 11.757188498402556}\n",
      "{'loss': 1.3558, 'grad_norm': 1.6813116073608398, 'learning_rate': 4.091054313099042e-05, 'epoch': 11.821086261980831}\n",
      "{'loss': 1.3573, 'grad_norm': 1.786325454711914, 'learning_rate': 4.059105431309904e-05, 'epoch': 11.884984025559106}\n",
      "{'loss': 1.3664, 'grad_norm': 1.8316658735275269, 'learning_rate': 4.027156549520767e-05, 'epoch': 11.94888178913738}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 3756\n",
      "\n",
      "Evaluating Step 3756 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 3756 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1610 (161/1000)\n",
      "Representation power: 0.0350 (35/1000)\n",
      "Creativity: 0.1240 (124/1000)\n",
      "Uniqueness (permutations): 0.1590 (159/1000)\n",
      "Uniqueness (strings): 0.9990 (999/1000)\n",
      "\n",
      "Evaluating Step 3756 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1560 (156/1000)\n",
      "Representation power: 0.0300 (30/1000)\n",
      "Creativity: 0.1240 (124/1000)\n",
      "Uniqueness (permutations): 0.1540 (154/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 3756 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1810 (181/1000)\n",
      "Representation power: 0.0410 (41/1000)\n",
      "Creativity: 0.1380 (138/1000)\n",
      "Uniqueness (permutations): 0.1790 (179/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 3756 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2200 (220/1000)\n",
      "Representation power: 0.0550 (55/1000)\n",
      "Creativity: 0.1640 (164/1000)\n",
      "Uniqueness (permutations): 0.2190 (219/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 3756 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1010 (101/1000)\n",
      "Representation power: 0.0220 (22/1000)\n",
      "Creativity: 0.0790 (79/1000)\n",
      "Uniqueness (permutations): 0.1010 (101/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 3756\n",
      "âœ… Evaluation logged and saved at step 3756\n",
      "{'loss': 1.3521, 'grad_norm': 1.673229455947876, 'learning_rate': 3.99520766773163e-05, 'epoch': 12.012779552715655}\n",
      "{'loss': 1.2872, 'grad_norm': 1.641963005065918, 'learning_rate': 3.9632587859424926e-05, 'epoch': 12.07667731629393}\n",
      "{'loss': 1.2907, 'grad_norm': 1.7538695335388184, 'learning_rate': 3.931309904153355e-05, 'epoch': 12.140575079872205}\n",
      "{'loss': 1.2942, 'grad_norm': 1.7148091793060303, 'learning_rate': 3.8993610223642176e-05, 'epoch': 12.204472843450478}\n",
      "{'loss': 1.2941, 'grad_norm': 1.8319761753082275, 'learning_rate': 3.8674121405750805e-05, 'epoch': 12.268370607028753}\n",
      "{'loss': 1.2992, 'grad_norm': 1.7731354236602783, 'learning_rate': 3.835463258785943e-05, 'epoch': 12.332268370607029}\n",
      "{'loss': 1.3046, 'grad_norm': 1.748792052268982, 'learning_rate': 3.803514376996805e-05, 'epoch': 12.396166134185304}\n",
      "{'loss': 1.307, 'grad_norm': 1.7600486278533936, 'learning_rate': 3.771565495207668e-05, 'epoch': 12.460063897763579}\n",
      "{'loss': 1.307, 'grad_norm': 1.7680528163909912, 'learning_rate': 3.7396166134185306e-05, 'epoch': 12.523961661341852}\n",
      "{'loss': 1.3112, 'grad_norm': 1.7044587135314941, 'learning_rate': 3.7076677316293935e-05, 'epoch': 12.587859424920127}\n",
      "{'loss': 1.3104, 'grad_norm': 1.8693054914474487, 'learning_rate': 3.6757188498402556e-05, 'epoch': 12.651757188498403}\n",
      "{'loss': 1.3195, 'grad_norm': 1.7290595769882202, 'learning_rate': 3.6437699680511185e-05, 'epoch': 12.715654952076678}\n",
      "{'loss': 1.319, 'grad_norm': 1.8315926790237427, 'learning_rate': 3.6118210862619814e-05, 'epoch': 12.779552715654953}\n",
      "{'loss': 1.3146, 'grad_norm': 1.8043652772903442, 'learning_rate': 3.5798722044728436e-05, 'epoch': 12.843450479233226}\n",
      "{'loss': 1.3158, 'grad_norm': 1.6677323579788208, 'learning_rate': 3.5479233226837064e-05, 'epoch': 12.907348242811501}\n",
      "{'loss': 1.3289, 'grad_norm': 1.7714959383010864, 'learning_rate': 3.5159744408945686e-05, 'epoch': 12.971246006389777}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 4069\n",
      "\n",
      "Evaluating Step 4069 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 4069 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1690 (169/1000)\n",
      "Representation power: 0.0400 (40/1000)\n",
      "Creativity: 0.1260 (126/1000)\n",
      "Uniqueness (permutations): 0.1660 (166/1000)\n",
      "Uniqueness (strings): 0.9940 (994/1000)\n",
      "\n",
      "Evaluating Step 4069 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1640 (164/1000)\n",
      "Representation power: 0.0330 (33/1000)\n",
      "Creativity: 0.1290 (129/1000)\n",
      "Uniqueness (permutations): 0.1620 (162/1000)\n",
      "Uniqueness (strings): 0.9990 (999/1000)\n",
      "\n",
      "Evaluating Step 4069 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1940 (194/1000)\n",
      "Representation power: 0.0400 (40/1000)\n",
      "Creativity: 0.1530 (153/1000)\n",
      "Uniqueness (permutations): 0.1930 (193/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 4069 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2090 (209/1000)\n",
      "Representation power: 0.0340 (34/1000)\n",
      "Creativity: 0.1740 (174/1000)\n",
      "Uniqueness (permutations): 0.2080 (208/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 4069 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1070 (107/1000)\n",
      "Representation power: 0.0270 (27/1000)\n",
      "Creativity: 0.0800 (80/1000)\n",
      "Uniqueness (permutations): 0.1070 (107/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 4069\n",
      "âœ… Evaluation logged and saved at step 4069\n",
      "{'loss': 1.2726, 'grad_norm': 1.702703833580017, 'learning_rate': 3.4840255591054315e-05, 'epoch': 13.035143769968052}\n",
      "{'loss': 1.2522, 'grad_norm': 1.7140429019927979, 'learning_rate': 3.452076677316294e-05, 'epoch': 13.099041533546325}\n",
      "{'loss': 1.2433, 'grad_norm': 1.7155145406723022, 'learning_rate': 3.4201277955271565e-05, 'epoch': 13.1629392971246}\n",
      "{'loss': 1.2572, 'grad_norm': 1.761357069015503, 'learning_rate': 3.3881789137380194e-05, 'epoch': 13.226837060702875}\n",
      "{'loss': 1.2512, 'grad_norm': 1.814590334892273, 'learning_rate': 3.356230031948882e-05, 'epoch': 13.29073482428115}\n",
      "{'loss': 1.2596, 'grad_norm': 1.8129158020019531, 'learning_rate': 3.324281150159745e-05, 'epoch': 13.354632587859426}\n",
      "{'loss': 1.2695, 'grad_norm': 1.9999339580535889, 'learning_rate': 3.292332268370607e-05, 'epoch': 13.418530351437699}\n",
      "{'loss': 1.2762, 'grad_norm': 1.8350224494934082, 'learning_rate': 3.2603833865814695e-05, 'epoch': 13.482428115015974}\n",
      "{'loss': 1.2621, 'grad_norm': 1.7209410667419434, 'learning_rate': 3.228434504792332e-05, 'epoch': 13.54632587859425}\n",
      "{'loss': 1.2744, 'grad_norm': 1.8186157941818237, 'learning_rate': 3.196485623003195e-05, 'epoch': 13.610223642172524}\n",
      "{'loss': 1.2794, 'grad_norm': 1.715632438659668, 'learning_rate': 3.1645367412140574e-05, 'epoch': 13.6741214057508}\n",
      "{'loss': 1.2778, 'grad_norm': 1.847609281539917, 'learning_rate': 3.13258785942492e-05, 'epoch': 13.738019169329073}\n",
      "{'loss': 1.283, 'grad_norm': 1.8503390550613403, 'learning_rate': 3.100638977635783e-05, 'epoch': 13.801916932907348}\n",
      "{'loss': 1.2781, 'grad_norm': 1.7775371074676514, 'learning_rate': 3.068690095846645e-05, 'epoch': 13.865814696485623}\n",
      "{'loss': 1.29, 'grad_norm': 1.8914341926574707, 'learning_rate': 3.036741214057508e-05, 'epoch': 13.929712460063898}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2743, 'grad_norm': 1.892744541168213, 'learning_rate': 3.0047923322683707e-05, 'epoch': 13.993610223642172}\n",
      "\n",
      "ðŸ“ˆ Live evaluation at step 4382\n",
      "\n",
      "Evaluating Step 4382 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 4382 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1550 (155/1000)\n",
      "Representation power: 0.0400 (40/1000)\n",
      "Creativity: 0.1100 (110/1000)\n",
      "Uniqueness (permutations): 0.1500 (150/1000)\n",
      "Uniqueness (strings): 0.9910 (991/1000)\n",
      "\n",
      "Evaluating Step 4382 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1850 (185/1000)\n",
      "Representation power: 0.0400 (40/1000)\n",
      "Creativity: 0.1430 (143/1000)\n",
      "Uniqueness (permutations): 0.1830 (183/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 4382 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1960 (196/1000)\n",
      "Representation power: 0.0400 (40/1000)\n",
      "Creativity: 0.1550 (155/1000)\n",
      "Uniqueness (permutations): 0.1950 (195/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 4382 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2120 (212/1000)\n",
      "Representation power: 0.0480 (48/1000)\n",
      "Creativity: 0.1630 (163/1000)\n",
      "Uniqueness (permutations): 0.2110 (211/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 4382 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1080 (108/1000)\n",
      "Representation power: 0.0210 (21/1000)\n",
      "Creativity: 0.0860 (86/1000)\n",
      "Uniqueness (permutations): 0.1070 (107/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 4382\n",
      "âœ… Evaluation logged and saved at step 4382\n",
      "{'loss': 1.223, 'grad_norm': 1.7531120777130127, 'learning_rate': 2.9728434504792335e-05, 'epoch': 14.057507987220447}\n",
      "{'loss': 1.2126, 'grad_norm': 1.8110153675079346, 'learning_rate': 2.9408945686900957e-05, 'epoch': 14.121405750798722}\n",
      "{'loss': 1.2169, 'grad_norm': 1.8782826662063599, 'learning_rate': 2.9089456869009586e-05, 'epoch': 14.185303514376997}\n",
      "{'loss': 1.2165, 'grad_norm': 1.808288335800171, 'learning_rate': 2.876996805111821e-05, 'epoch': 14.249201277955272}\n",
      "{'loss': 1.2166, 'grad_norm': 1.8090754747390747, 'learning_rate': 2.845047923322684e-05, 'epoch': 14.313099041533546}\n",
      "{'loss': 1.2303, 'grad_norm': 1.7871769666671753, 'learning_rate': 2.813099041533546e-05, 'epoch': 14.37699680511182}\n",
      "{'loss': 1.2312, 'grad_norm': 1.9286988973617554, 'learning_rate': 2.781150159744409e-05, 'epoch': 14.440894568690096}\n",
      "{'loss': 1.2347, 'grad_norm': 1.757990837097168, 'learning_rate': 2.7492012779552716e-05, 'epoch': 14.504792332268371}\n",
      "{'loss': 1.2447, 'grad_norm': 1.7650941610336304, 'learning_rate': 2.7172523961661344e-05, 'epoch': 14.568690095846645}\n",
      "{'loss': 1.2333, 'grad_norm': 1.833263635635376, 'learning_rate': 2.6853035143769966e-05, 'epoch': 14.63258785942492}\n",
      "{'loss': 1.2332, 'grad_norm': 1.8221553564071655, 'learning_rate': 2.6533546325878595e-05, 'epoch': 14.696485623003195}\n",
      "{'loss': 1.2465, 'grad_norm': 1.9527623653411865, 'learning_rate': 2.6214057507987223e-05, 'epoch': 14.76038338658147}\n",
      "{'loss': 1.2382, 'grad_norm': 1.823050856590271, 'learning_rate': 2.589456869009585e-05, 'epoch': 14.824281150159745}\n",
      "{'loss': 1.2496, 'grad_norm': 1.8915317058563232, 'learning_rate': 2.557507987220447e-05, 'epoch': 14.888178913738018}\n",
      "{'loss': 1.2428, 'grad_norm': 1.8633973598480225, 'learning_rate': 2.52555910543131e-05, 'epoch': 14.952076677316294}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 4695\n",
      "\n",
      "Evaluating Step 4695 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 1.0000 (1000/1000)\n",
      "Representation power: 0.0010 (1/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0010 (1/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 4695 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1930 (193/1000)\n",
      "Representation power: 0.0510 (51/1000)\n",
      "Creativity: 0.1330 (133/1000)\n",
      "Uniqueness (permutations): 0.1840 (184/1000)\n",
      "Uniqueness (strings): 0.9870 (987/1000)\n",
      "\n",
      "Evaluating Step 4695 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2020 (202/1000)\n",
      "Representation power: 0.0440 (44/1000)\n",
      "Creativity: 0.1570 (157/1000)\n",
      "Uniqueness (permutations): 0.2010 (201/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 4695 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2200 (220/1000)\n",
      "Representation power: 0.0450 (45/1000)\n",
      "Creativity: 0.1740 (174/1000)\n",
      "Uniqueness (permutations): 0.2190 (219/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 4695 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2090 (209/1000)\n",
      "Representation power: 0.0450 (45/1000)\n",
      "Creativity: 0.1640 (164/1000)\n",
      "Uniqueness (permutations): 0.2090 (209/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 4695 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1140 (114/1000)\n",
      "Representation power: 0.0230 (23/1000)\n",
      "Creativity: 0.0900 (90/1000)\n",
      "Uniqueness (permutations): 0.1130 (113/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 4695\n",
      "âœ… Evaluation logged and saved at step 4695\n",
      "{'loss': 1.2371, 'grad_norm': 1.814712405204773, 'learning_rate': 2.4936102236421728e-05, 'epoch': 15.015974440894569}\n",
      "{'loss': 1.186, 'grad_norm': 1.8587862253189087, 'learning_rate': 2.4616613418530353e-05, 'epoch': 15.079872204472844}\n",
      "{'loss': 1.1919, 'grad_norm': 1.9700162410736084, 'learning_rate': 2.4297124600638978e-05, 'epoch': 15.143769968051119}\n",
      "{'loss': 1.1925, 'grad_norm': 1.8170162439346313, 'learning_rate': 2.3977635782747603e-05, 'epoch': 15.207667731629392}\n",
      "{'loss': 1.1821, 'grad_norm': 1.8744592666625977, 'learning_rate': 2.3658146964856232e-05, 'epoch': 15.271565495207668}\n",
      "{'loss': 1.1964, 'grad_norm': 1.8722474575042725, 'learning_rate': 2.3338658146964857e-05, 'epoch': 15.335463258785943}\n",
      "{'loss': 1.1927, 'grad_norm': 1.9312041997909546, 'learning_rate': 2.3019169329073482e-05, 'epoch': 15.399361022364218}\n",
      "{'loss': 1.2011, 'grad_norm': 1.8606494665145874, 'learning_rate': 2.2699680511182108e-05, 'epoch': 15.463258785942491}\n",
      "{'loss': 1.2073, 'grad_norm': 1.9035868644714355, 'learning_rate': 2.2380191693290736e-05, 'epoch': 15.527156549520766}\n",
      "{'loss': 1.211, 'grad_norm': 1.8589941263198853, 'learning_rate': 2.206070287539936e-05, 'epoch': 15.591054313099042}\n",
      "{'loss': 1.2049, 'grad_norm': 1.8391098976135254, 'learning_rate': 2.174121405750799e-05, 'epoch': 15.654952076677317}\n",
      "{'loss': 1.1991, 'grad_norm': 1.8872058391571045, 'learning_rate': 2.1421725239616612e-05, 'epoch': 15.718849840255592}\n",
      "{'loss': 1.21, 'grad_norm': 1.8460932970046997, 'learning_rate': 2.110223642172524e-05, 'epoch': 15.782747603833865}\n",
      "{'loss': 1.2086, 'grad_norm': 2.034829616546631, 'learning_rate': 2.0782747603833866e-05, 'epoch': 15.84664536741214}\n",
      "{'loss': 1.2134, 'grad_norm': 1.9526318311691284, 'learning_rate': 2.0463258785942495e-05, 'epoch': 15.910543130990416}\n",
      "{'loss': 1.2122, 'grad_norm': 1.9303128719329834, 'learning_rate': 2.014376996805112e-05, 'epoch': 15.97444089456869}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 5008\n",
      "\n",
      "Evaluating Step 5008 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 5008 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2010 (201/1000)\n",
      "Representation power: 0.0640 (64/1000)\n",
      "Creativity: 0.1330 (133/1000)\n",
      "Uniqueness (permutations): 0.1970 (197/1000)\n",
      "Uniqueness (strings): 0.9900 (990/1000)\n",
      "\n",
      "Evaluating Step 5008 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1870 (187/1000)\n",
      "Representation power: 0.0400 (40/1000)\n",
      "Creativity: 0.1470 (147/1000)\n",
      "Uniqueness (permutations): 0.1870 (187/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 5008 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1960 (196/1000)\n",
      "Representation power: 0.0430 (43/1000)\n",
      "Creativity: 0.1520 (152/1000)\n",
      "Uniqueness (permutations): 0.1950 (195/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 5008 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2280 (228/1000)\n",
      "Representation power: 0.0520 (52/1000)\n",
      "Creativity: 0.1750 (175/1000)\n",
      "Uniqueness (permutations): 0.2270 (227/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 5008 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1110 (111/1000)\n",
      "Representation power: 0.0210 (21/1000)\n",
      "Creativity: 0.0890 (89/1000)\n",
      "Uniqueness (permutations): 0.1100 (110/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 5008\n",
      "âœ… Evaluation logged and saved at step 5008\n",
      "{'loss': 1.1726, 'grad_norm': 1.7098149061203003, 'learning_rate': 1.9824281150159745e-05, 'epoch': 16.038338658146966}\n",
      "{'loss': 1.1721, 'grad_norm': 1.8297719955444336, 'learning_rate': 1.950479233226837e-05, 'epoch': 16.10223642172524}\n",
      "{'loss': 1.1623, 'grad_norm': 1.8314894437789917, 'learning_rate': 1.9185303514377e-05, 'epoch': 16.166134185303516}\n",
      "{'loss': 1.1632, 'grad_norm': 1.9872431755065918, 'learning_rate': 1.8865814696485624e-05, 'epoch': 16.230031948881788}\n",
      "{'loss': 1.1706, 'grad_norm': 1.8443249464035034, 'learning_rate': 1.854632587859425e-05, 'epoch': 16.293929712460063}\n",
      "{'loss': 1.1727, 'grad_norm': 1.92386794090271, 'learning_rate': 1.8226837060702875e-05, 'epoch': 16.357827476038338}\n",
      "{'loss': 1.1703, 'grad_norm': 1.8570119142532349, 'learning_rate': 1.7907348242811503e-05, 'epoch': 16.421725239616613}\n",
      "{'loss': 1.1789, 'grad_norm': 2.0141818523406982, 'learning_rate': 1.758785942492013e-05, 'epoch': 16.48562300319489}\n",
      "{'loss': 1.1734, 'grad_norm': 1.8708887100219727, 'learning_rate': 1.7268370607028757e-05, 'epoch': 16.549520766773163}\n",
      "{'loss': 1.1719, 'grad_norm': 1.9694472551345825, 'learning_rate': 1.694888178913738e-05, 'epoch': 16.61341853035144}\n",
      "{'loss': 1.1782, 'grad_norm': 2.020291566848755, 'learning_rate': 1.6629392971246008e-05, 'epoch': 16.677316293929714}\n",
      "{'loss': 1.1835, 'grad_norm': 1.8735765218734741, 'learning_rate': 1.6309904153354633e-05, 'epoch': 16.74121405750799}\n",
      "{'loss': 1.1776, 'grad_norm': 1.9522618055343628, 'learning_rate': 1.599041533546326e-05, 'epoch': 16.80511182108626}\n",
      "{'loss': 1.1845, 'grad_norm': 1.8854553699493408, 'learning_rate': 1.5670926517571887e-05, 'epoch': 16.869009584664536}\n",
      "{'loss': 1.1811, 'grad_norm': 1.9164987802505493, 'learning_rate': 1.5351437699680512e-05, 'epoch': 16.93290734824281}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1823, 'grad_norm': 1.8959641456604004, 'learning_rate': 1.5031948881789137e-05, 'epoch': 16.996805111821086}\n",
      "\n",
      "ðŸ“ˆ Live evaluation at step 5321\n",
      "\n",
      "Evaluating Step 5321 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 5321 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2150 (215/1000)\n",
      "Representation power: 0.0550 (55/1000)\n",
      "Creativity: 0.1480 (148/1000)\n",
      "Uniqueness (permutations): 0.2030 (203/1000)\n",
      "Uniqueness (strings): 0.9880 (988/1000)\n",
      "\n",
      "Evaluating Step 5321 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2190 (219/1000)\n",
      "Representation power: 0.0530 (53/1000)\n",
      "Creativity: 0.1630 (163/1000)\n",
      "Uniqueness (permutations): 0.2160 (216/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 5321 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2080 (208/1000)\n",
      "Representation power: 0.0410 (41/1000)\n",
      "Creativity: 0.1650 (165/1000)\n",
      "Uniqueness (permutations): 0.2060 (206/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 5321 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2110 (211/1000)\n",
      "Representation power: 0.0510 (51/1000)\n",
      "Creativity: 0.1600 (160/1000)\n",
      "Uniqueness (permutations): 0.2110 (211/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 5321 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1200 (120/1000)\n",
      "Representation power: 0.0190 (19/1000)\n",
      "Creativity: 0.1010 (101/1000)\n",
      "Uniqueness (permutations): 0.1200 (120/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 5321\n",
      "âœ… Evaluation logged and saved at step 5321\n",
      "{'loss': 1.1388, 'grad_norm': 1.8135318756103516, 'learning_rate': 1.4712460063897766e-05, 'epoch': 17.06070287539936}\n",
      "{'loss': 1.1571, 'grad_norm': 1.8337044715881348, 'learning_rate': 1.439297124600639e-05, 'epoch': 17.124600638977636}\n",
      "{'loss': 1.1483, 'grad_norm': 1.915152668952942, 'learning_rate': 1.4073482428115018e-05, 'epoch': 17.18849840255591}\n",
      "{'loss': 1.1517, 'grad_norm': 1.8920063972473145, 'learning_rate': 1.3753993610223642e-05, 'epoch': 17.252396166134186}\n",
      "{'loss': 1.1499, 'grad_norm': 1.8284590244293213, 'learning_rate': 1.343450479233227e-05, 'epoch': 17.31629392971246}\n",
      "{'loss': 1.1532, 'grad_norm': 1.9091908931732178, 'learning_rate': 1.3115015974440895e-05, 'epoch': 17.380191693290733}\n",
      "{'loss': 1.1394, 'grad_norm': 1.9489160776138306, 'learning_rate': 1.2795527156549522e-05, 'epoch': 17.44408945686901}\n",
      "{'loss': 1.1629, 'grad_norm': 1.8651822805404663, 'learning_rate': 1.2476038338658148e-05, 'epoch': 17.507987220447284}\n",
      "{'loss': 1.1515, 'grad_norm': 1.9356848001480103, 'learning_rate': 1.2156549520766773e-05, 'epoch': 17.57188498402556}\n",
      "{'loss': 1.1576, 'grad_norm': 2.0465314388275146, 'learning_rate': 1.18370607028754e-05, 'epoch': 17.635782747603834}\n",
      "{'loss': 1.154, 'grad_norm': 1.8800410032272339, 'learning_rate': 1.1517571884984025e-05, 'epoch': 17.69968051118211}\n",
      "{'loss': 1.1472, 'grad_norm': 1.949187994003296, 'learning_rate': 1.1198083067092652e-05, 'epoch': 17.763578274760384}\n",
      "{'loss': 1.1483, 'grad_norm': 1.9723113775253296, 'learning_rate': 1.0878594249201277e-05, 'epoch': 17.82747603833866}\n",
      "{'loss': 1.1615, 'grad_norm': 1.965228796005249, 'learning_rate': 1.0559105431309904e-05, 'epoch': 17.891373801916934}\n",
      "{'loss': 1.1552, 'grad_norm': 1.9333009719848633, 'learning_rate': 1.0239616613418531e-05, 'epoch': 17.955271565495206}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 5634\n",
      "\n",
      "Evaluating Step 5634 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 1.0000 (1000/1000)\n",
      "Representation power: 0.0010 (1/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0010 (1/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 5634 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2150 (215/1000)\n",
      "Representation power: 0.0680 (68/1000)\n",
      "Creativity: 0.1350 (135/1000)\n",
      "Uniqueness (permutations): 0.2030 (203/1000)\n",
      "Uniqueness (strings): 0.9860 (986/1000)\n",
      "\n",
      "Evaluating Step 5634 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2030 (203/1000)\n",
      "Representation power: 0.0520 (52/1000)\n",
      "Creativity: 0.1490 (149/1000)\n",
      "Uniqueness (permutations): 0.2010 (201/1000)\n",
      "Uniqueness (strings): 0.9990 (999/1000)\n",
      "\n",
      "Evaluating Step 5634 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2000 (200/1000)\n",
      "Representation power: 0.0440 (44/1000)\n",
      "Creativity: 0.1540 (154/1000)\n",
      "Uniqueness (permutations): 0.1980 (198/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 5634 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2020 (202/1000)\n",
      "Representation power: 0.0470 (47/1000)\n",
      "Creativity: 0.1550 (155/1000)\n",
      "Uniqueness (permutations): 0.2020 (202/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 5634 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1190 (119/1000)\n",
      "Representation power: 0.0240 (24/1000)\n",
      "Creativity: 0.0950 (95/1000)\n",
      "Uniqueness (permutations): 0.1190 (119/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 5634\n",
      "âœ… Evaluation logged and saved at step 5634\n",
      "{'loss': 1.1563, 'grad_norm': 1.9515082836151123, 'learning_rate': 9.920127795527156e-06, 'epoch': 18.01916932907348}\n",
      "{'loss': 1.1261, 'grad_norm': 1.854538083076477, 'learning_rate': 9.600638977635783e-06, 'epoch': 18.083067092651756}\n",
      "{'loss': 1.1204, 'grad_norm': 1.8746358156204224, 'learning_rate': 9.281150159744408e-06, 'epoch': 18.14696485623003}\n",
      "{'loss': 1.137, 'grad_norm': 1.8406565189361572, 'learning_rate': 8.961661341853035e-06, 'epoch': 18.210862619808307}\n",
      "{'loss': 1.1341, 'grad_norm': 1.8348321914672852, 'learning_rate': 8.64217252396166e-06, 'epoch': 18.27476038338658}\n",
      "{'loss': 1.132, 'grad_norm': 1.9526658058166504, 'learning_rate': 8.322683706070288e-06, 'epoch': 18.338658146964857}\n",
      "{'loss': 1.1231, 'grad_norm': 1.9517747163772583, 'learning_rate': 8.003194888178915e-06, 'epoch': 18.402555910543132}\n",
      "{'loss': 1.1397, 'grad_norm': 2.0503904819488525, 'learning_rate': 7.68370607028754e-06, 'epoch': 18.466453674121407}\n",
      "{'loss': 1.1334, 'grad_norm': 1.8548903465270996, 'learning_rate': 7.364217252396166e-06, 'epoch': 18.53035143769968}\n",
      "{'loss': 1.1269, 'grad_norm': 1.851588487625122, 'learning_rate': 7.044728434504792e-06, 'epoch': 18.594249201277954}\n",
      "{'loss': 1.1458, 'grad_norm': 1.9178811311721802, 'learning_rate': 6.725239616613419e-06, 'epoch': 18.65814696485623}\n",
      "{'loss': 1.1335, 'grad_norm': 1.8802372217178345, 'learning_rate': 6.405750798722045e-06, 'epoch': 18.722044728434504}\n",
      "{'loss': 1.1363, 'grad_norm': 1.918531894683838, 'learning_rate': 6.086261980830671e-06, 'epoch': 18.78594249201278}\n",
      "{'loss': 1.1351, 'grad_norm': 1.9366166591644287, 'learning_rate': 5.766773162939297e-06, 'epoch': 18.849840255591054}\n",
      "{'loss': 1.1424, 'grad_norm': 1.9805221557617188, 'learning_rate': 5.447284345047923e-06, 'epoch': 18.91373801916933}\n",
      "{'loss': 1.1462, 'grad_norm': 1.9666322469711304, 'learning_rate': 5.127795527156549e-06, 'epoch': 18.977635782747605}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 5947\n",
      "\n",
      "Evaluating Step 5947 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 5947 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2120 (212/1000)\n",
      "Representation power: 0.0590 (59/1000)\n",
      "Creativity: 0.1370 (137/1000)\n",
      "Uniqueness (permutations): 0.1960 (196/1000)\n",
      "Uniqueness (strings): 0.9880 (988/1000)\n",
      "\n",
      "Evaluating Step 5947 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1830 (183/1000)\n",
      "Representation power: 0.0490 (49/1000)\n",
      "Creativity: 0.1310 (131/1000)\n",
      "Uniqueness (permutations): 0.1800 (180/1000)\n",
      "Uniqueness (strings): 0.9990 (999/1000)\n",
      "\n",
      "Evaluating Step 5947 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2110 (211/1000)\n",
      "Representation power: 0.0410 (41/1000)\n",
      "Creativity: 0.1680 (168/1000)\n",
      "Uniqueness (permutations): 0.2090 (209/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 5947 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2170 (217/1000)\n",
      "Representation power: 0.0480 (48/1000)\n",
      "Creativity: 0.1690 (169/1000)\n",
      "Uniqueness (permutations): 0.2170 (217/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 5947 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1170 (117/1000)\n",
      "Representation power: 0.0190 (19/1000)\n",
      "Creativity: 0.0970 (97/1000)\n",
      "Uniqueness (permutations): 0.1160 (116/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 5947\n",
      "âœ… Evaluation logged and saved at step 5947\n",
      "{'loss': 1.1273, 'grad_norm': 1.8181618452072144, 'learning_rate': 4.808306709265175e-06, 'epoch': 19.04153354632588}\n",
      "{'loss': 1.1245, 'grad_norm': 1.8070778846740723, 'learning_rate': 4.4888178913738015e-06, 'epoch': 19.105431309904155}\n",
      "{'loss': 1.1161, 'grad_norm': 1.7990829944610596, 'learning_rate': 4.169329073482428e-06, 'epoch': 19.169329073482427}\n",
      "{'loss': 1.1242, 'grad_norm': 1.8957017660140991, 'learning_rate': 3.8498402555910545e-06, 'epoch': 19.233226837060702}\n",
      "{'loss': 1.1178, 'grad_norm': 1.9252512454986572, 'learning_rate': 3.5303514376996806e-06, 'epoch': 19.297124600638977}\n",
      "{'loss': 1.1179, 'grad_norm': 1.8588632345199585, 'learning_rate': 3.2108626198083067e-06, 'epoch': 19.361022364217252}\n",
      "{'loss': 1.1244, 'grad_norm': 1.964561104774475, 'learning_rate': 2.891373801916933e-06, 'epoch': 19.424920127795527}\n",
      "{'loss': 1.1175, 'grad_norm': 1.879854679107666, 'learning_rate': 2.5718849840255593e-06, 'epoch': 19.488817891373802}\n",
      "{'loss': 1.131, 'grad_norm': 1.8439351320266724, 'learning_rate': 2.2523961661341854e-06, 'epoch': 19.552715654952078}\n",
      "{'loss': 1.1204, 'grad_norm': 1.907379388809204, 'learning_rate': 1.9329073482428114e-06, 'epoch': 19.616613418530353}\n",
      "{'loss': 1.1199, 'grad_norm': 1.7831695079803467, 'learning_rate': 1.6134185303514375e-06, 'epoch': 19.680511182108628}\n",
      "{'loss': 1.1126, 'grad_norm': 1.7539042234420776, 'learning_rate': 1.293929712460064e-06, 'epoch': 19.7444089456869}\n",
      "{'loss': 1.1159, 'grad_norm': 1.9693044424057007, 'learning_rate': 9.744408945686901e-07, 'epoch': 19.808306709265175}\n",
      "{'loss': 1.1212, 'grad_norm': 1.8158063888549805, 'learning_rate': 6.549520766773163e-07, 'epoch': 19.87220447284345}\n",
      "{'loss': 1.1258, 'grad_norm': 1.8646056652069092, 'learning_rate': 3.354632587859425e-07, 'epoch': 19.936102236421725}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Live evaluation at step 6260\n",
      "\n",
      "Evaluating Step 6260 argmax for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.0000 (0/1000)\n",
      "Representation power: 0.0000 (0/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness (permutations): 0.0000 (0/1000)\n",
      "Uniqueness (strings): 0.0010 (1/1000)\n",
      "\n",
      "Evaluating Step 6260 softmax @ temp=0.3 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2170 (217/1000)\n",
      "Representation power: 0.0630 (63/1000)\n",
      "Creativity: 0.1410 (141/1000)\n",
      "Uniqueness (permutations): 0.2040 (204/1000)\n",
      "Uniqueness (strings): 0.9890 (989/1000)\n",
      "\n",
      "Evaluating Step 6260 softmax @ temp=0.5 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2100 (210/1000)\n",
      "Representation power: 0.0570 (57/1000)\n",
      "Creativity: 0.1490 (149/1000)\n",
      "Uniqueness (permutations): 0.2060 (206/1000)\n",
      "Uniqueness (strings): 0.9990 (999/1000)\n",
      "\n",
      "Evaluating Step 6260 softmax @ temp=0.7 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2070 (207/1000)\n",
      "Representation power: 0.0390 (39/1000)\n",
      "Creativity: 0.1650 (165/1000)\n",
      "Uniqueness (permutations): 0.2040 (204/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 6260 softmax @ temp=1.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.2100 (210/1000)\n",
      "Representation power: 0.0460 (46/1000)\n",
      "Creativity: 0.1640 (164/1000)\n",
      "Uniqueness (permutations): 0.2100 (210/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "\n",
      "Evaluating Step 6260 softmax @ temp=2.0 for seed 42...\n",
      "\n",
      "Generating 1000 unconditional samples.\n",
      "Coherence: 0.1120 (112/1000)\n",
      "Representation power: 0.0210 (21/1000)\n",
      "Creativity: 0.0910 (91/1000)\n",
      "Uniqueness (permutations): 0.1120 (112/1000)\n",
      "Uniqueness (strings): 1.0000 (1000/1000)\n",
      "âœ… NLL distribution saved at step 6260\n",
      "âœ… Evaluation logged and saved at step 6260\n",
      "{'loss': 1.128, 'grad_norm': 2.6325953006744385, 'learning_rate': 1.597444089456869e-08, 'epoch': 20.0}\n",
      "{'train_runtime': 545.2635, 'train_samples_per_second': 366.795, 'train_steps_per_second': 11.481, 'train_loss': 1.4837885168032905, 'epoch': 20.0}\n",
      "\n",
      "âœ… Live evaluation complete. Results saved and logged to wandb.\n"
     ]
    }
   ],
   "source": [
    "train_main(\n",
    "    model=model,\n",
    "    dataset_name=dataset_name,\n",
    "    save_name=save_name,\n",
    "    hl=HL,\n",
    "    batch_size=batch_size,\n",
    "    num_epochs=epochs,\n",
    "    temperatures=[0.3, 0.5, 0.7, 1.0, 2.0],\n",
    "    num_eval_runs=eval_runs,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    "    device=DEVICE,\n",
    "    decode_fn=decode_batch,\n",
    "    eval_fn=evaluate_model,\n",
    "    num_checkpoints=num_ckpts,\n",
    "    log_to_wandb=False,\n",
    "    save_results=True, \n",
    "    lr=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae33d00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating 1000 unconditional samples.\n"
     ]
    }
   ],
   "source": [
    "samples = generate_samples(model, \n",
    "                                train_dataset, \n",
    "                                tokenizer,\n",
    "                                decode_fn=decode_batch, \n",
    "                                greedy=False, \n",
    "                                seed_tokens=SEED_TOKENS, \n",
    "                                seed_len=HL, \n",
    "                                max_length=train_dataset[1][\"labels\"].shape[0]*2,\n",
    "                                temperature=1.0, \n",
    "                                top_p=top_p, \n",
    "                                num_samples=num_eval_samples, \n",
    "                                batch_size=batch_size\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fcba5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence: 0.9340 (934/1000)\n",
      "Representation power: 0.0020 (2/1000)\n",
      "Creativity: 0.0000 (0/1000)\n",
      "Uniqueness: 0.0020 (2/1000)\n"
     ]
    }
   ],
   "source": [
    "tokenized_samples = [EVAL_TOKENIZER.encode(s) for s in samples]\n",
    "\n",
    "unique_perms = set()\n",
    "unique_coherent_perms = set()\n",
    "num_coherent = 0\n",
    "incoherent_samples = []\n",
    "# Final metrics loop\n",
    "for s in tokenized_samples:\n",
    "    pi = compute_canonical_permutation(s, N=N)\n",
    "    if pi is not None:\n",
    "        unique_perms.add(pi)\n",
    "        if is_coherent_after_walk(s, N=N, vocab_ids=VOCAB_IDs):\n",
    "            num_coherent += 1\n",
    "            unique_coherent_perms.add(pi)\n",
    "        else:\n",
    "            incoherent_samples.append(s)\n",
    "    else:\n",
    "        incoherent_samples.append(s)\n",
    "\n",
    "\n",
    "num_memorized = len([s for s in unique_coherent_perms if s in train_perms_set])\n",
    "num_creative = len([s for s in unique_coherent_perms if s not in train_perms_set])\n",
    "num_unique = len(unique_perms)\n",
    "\n",
    "representation_power = (num_memorized / len(samples))\n",
    "creativity = (num_creative / len(samples)) \n",
    "uniqueness = (num_unique / len(samples)) \n",
    "coherence = (num_coherent / len(samples)) \n",
    "# perplexity = compute_perplexity(model, test_dataset, batch_size=batch_size)\n",
    "\n",
    "# print(f\"Perplexity: {perplexity:.4f}\")\n",
    "print(f\"Coherence: {coherence:.4f} ({num_coherent}/{len(samples)})\")\n",
    "print(f\"Representation power: {representation_power:.4f} ({num_memorized}/{len(samples)})\")\n",
    "print(f\"Creativity: {creativity:.4f} ({num_creative}/{len(samples)})\")\n",
    "print(f\"Uniqueness: {uniqueness:.4f} ({num_unique}/{len(samples)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e34cef2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v17 v5 v0 v17 v5 v0',\n",
       " 'v12 v18 v18 v8 v8 v12',\n",
       " 'v9 v12 v12 v8 v8 v9',\n",
       " 'v10 v20 v26 v10 v20 v26',\n",
       " 'v18 v15 v15 v12 v12 v18',\n",
       " 'v9 v14 v14 v24 v24 v9',\n",
       " 'v19 v29 v24 v19 v29 v24',\n",
       " 'v19 v12 v12 v19 v12 v19',\n",
       " 'v15 v2 v2 v0 v0 v15',\n",
       " 'v5 v27 v27 v5 v27 v5']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
